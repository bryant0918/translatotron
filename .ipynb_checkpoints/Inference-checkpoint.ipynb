{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a9eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from train import prepare_dataloaders, load_model, load_checkpoint\n",
    "from hparams import create_hparams\n",
    "import argparse\n",
    "from loss_function import Tacotron2Loss, Iso_Tacotron2Loss\n",
    "from plotting_utils import save_spectrogram\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from audio_processing import dynamic_range_compression, dynamic_range_decompression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fa0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(checkpoint_path, audiofile, out_dir):\n",
    "    # Define needed transformations\n",
    "    resampler = T.Resample(44100, hparams.sampling_rate)\n",
    "    \n",
    "    melspectrogram = T.MelSpectrogram(sample_rate=hparams.sampling_rate,\n",
    "                                           n_fft=hparams.filter_length,\n",
    "                                           win_length=hparams.win_length,\n",
    "                                           hop_length=hparams.hop_length,\n",
    "                                           n_mels=hparams.n_mel_channels,\n",
    "                                           center=True,\n",
    "                                           pad_mode=\"reflect\",\n",
    "                                           power=2.0)\n",
    "        \n",
    "    power_spec = T.InverseMelScale(n_stft=hparams.filter_length // 2 + 1,\n",
    "                                   n_mels=hparams.n_mel_channels,\n",
    "                                   sample_rate=hparams.sampling_rate,\n",
    "                                   f_min=0.0)\n",
    "\n",
    "    griffin_lim = T.GriffinLim(n_fft=hparams.filter_length,\n",
    "                               win_length=hparams.win_length,\n",
    "                               hop_length=hparams.hop_length,\n",
    "                               power=2)\n",
    "\n",
    "    \n",
    "    # Preprocess\n",
    "    audio, sampling_rate = torchaudio.load(audiofile)\n",
    "    assert sampling_rate == 22050\n",
    "    mel_spec = melspectrogram(audio)\n",
    "    mel_spec_normed = dynamic_range_compression(mel_spec)\n",
    "    \n",
    "    \n",
    "    model = load_model(hparams)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hparams.learning_rate,\n",
    "                                 weight_decay=hparams.weight_decay)\n",
    "    \n",
    "    print(isochronic)\n",
    "    if isochronic:\n",
    "        criterion = Iso_Tacotron2Loss()\n",
    "    else:\n",
    "        criterion = Tacotron2Loss()\n",
    "\n",
    "    model, _, _, _ = load_checkpoint(checkpoint_path, model, optimizer)\n",
    "\n",
    "        \n",
    "    \"\"\"Run Inference\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mel_pred, mel_postnet, gate, alignments = model.inference(mel_spec_normed[0])\n",
    "        print(\"mel_pred shape\", mel_pred.shape)\n",
    "\n",
    "        # Get denormalized signal for visualization and audio\n",
    "        out_sig = dynamic_range_decompression(mel_pred, .2)\n",
    "\n",
    "        # Show or save Spectrogram\n",
    "        save_spectrogram(out_sig, os.path.join(out_dir, \"mel_spec.png\"))\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        reduced_test_loss = loss.item()\n",
    "        test_loss += reduced_test_loss\n",
    "\n",
    "        # Get waveform from spectrogram\n",
    "        powr_spec = power_spec(out_sig)  # This can handle y_pred and do the whole batch\n",
    "        reconstructed_waveform = griffin_lim(powr_spec)\n",
    "\n",
    "        # Save output audio\n",
    "        torchaudio.save(os.path.join(out_dir, \"predicted_audio.wav\"), reconstructed_waveform, hparams.sampling_rate)\n",
    "\n",
    "        if i == 3:\n",
    "            break\n",
    "    test_loss = test_loss / (i + 1)\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110cd294",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"C:\\\\Users\\\\bryan\\\\Documents\\\\School\\\\Winter 2023\\\\CS 601R\\\\Final Project\\\\ckpts\\\\checkpoint_940\"\n",
    "audiofile = \"C:\\\\Users\\\\bryan\\\\Documents\\\\School\\\\Winter 2023\\\\CS 601R\\\\Final Project\\\\Data\\\\LibriS2S\\\\DE\\\\9\\\\sentence_level_audio\\\\00001-das_bildnis_4.flac\"\n",
    "out_dir = \"C:\\\\Users\\\\bryan\\\\Documents\\\\School\\\\Winter 2023\\\\CS 601R\\\\Final Project\\\\Output\\\\inference\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a493a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
